"""
Ablation Study: Adaptive vs. Non-Adaptive Analysis Approach Performance (Step 3)

Description:
    This script conducts an ablation study to compare the performance of the
    multi-adapter pedestrian analysis approach under two different operational modes.
    It uses the raw data generated by the inference scripts (Step 2) to simulate
    the computational cost (GFLOPs) and latency (inference time) of the approach.

Operational Modes:
    -   `ALL` Mode (Baseline):
        This mode simulates a non-adaptive, brute-force approach. It assumes all
        behavioral adapters are fired for every pedestrian in every frame, and all
        scene-level adapters are fired periodically (e.g., every 30 frames).
        This represents the maximum computational cost and information gain.

    -   `ADAPTIVE` Mode (Optimized):
        This mode simulates an intelligent, rule-based system that selectively
        fires adapters based on the current scene context. The rules are designed
        to minimize redundant computations by only activating adapters when the
        environment (e.g., weather, time of day, pedestrian density) justifies
        their use.

The pipeline operates as follows:
    1.  Loads the raw scene context and pedestrian behavior data from the CSV
        files generated in Step 2.
    2.  Calculates data-driven default values for adapter GFLOPs and inference
        times to handle any missing data points.
    3.  Simulates the `ALL` mode to establish a performance baseline.
    4.  Simulates the `ADAPTIVE` mode using the predefined decision rules.
    5.  Generates a comparative bar plot (`adaptive_vs_all_ablation.png`) to
        visualize the performance differences.
    6.  Generates a detailed markdown report (`ablation_report.md`) with a
        statistical breakdown of the results, including percentage changes.

Inputs:
    -   Scene Context Data: Path specified by `--scene_csv`.
        (Default: `raw_data_scene_contextual_analysis_step2.csv`)
    -   Pedestrian Behavior Data: Path specified by `--behavior_csv`.
        (Default: `raw_data_pedestrian_behavior_analysis_step2.csv`)

Outputs:
    -   Ablation Study Plot: `Ablation_Studies_Report/adaptive_vs_all_ablation.png`
    -   Ablation Study Report: `Ablation_Studies_Report/ablation_report.md`

Command-Line Arguments:
    -   `--scene_csv` (str, optional):
        Path to the CSV file containing the scene contextual analysis results.
    -   `--behavior_csv` (str, optional):
        Path to the CSV file containing the pedestrian behavior analysis results.
"""
from __future__ import annotations

import os
from pathlib import Path
from typing import Optional, Dict

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import argparse

# =============================================================================
# A. CONFIGURATION & DATA HANDLING
# =============================================================================
sns.set_theme(style="whitegrid", context="paper", font_scale=1.1)
COLORS = ["#004488", "#DDAA33", "#BB5566", "#FF5733"]
ABLATION_DIR = Path("Ablation_Studies_Report")

def load_ablation_data(scene_csv: str, behavior_csv: Optional[str] = None) -> tuple[pd.DataFrame, pd.DataFrame | None]:
    """Loads and prepares the scene and behavior data for the ablation study."""
    print("Loading data for ablation studies...")
    if not os.path.exists(scene_csv):
        raise FileNotFoundError(f"Scene data CSV not found at: {scene_csv}")
    
    scene_df = pd.read_csv(scene_csv)
    print(f"   - Scene data loaded: {len(scene_df):,} rows")

    behavior_df = None
    if behavior_csv and os.path.exists(behavior_csv):
        behavior_df = pd.read_csv(behavior_csv)
        print(f"   - Behavior data loaded: {len(behavior_df):,} rows")
    else:
        print("   - Warning: Behavior data CSV not found or not provided. Some metrics may be unavailable.")

    return scene_df, behavior_df

def calculate_default_metrics(scene_df: pd.DataFrame, behavior_df: Optional[pd.DataFrame] = None) -> Dict[str, float]:
    """
    Calculates average inference time and GFLOPs from the raw data. These values
    are used as fallbacks for any adapters where performance metrics are missing.
    """
    print("\nCalculating data-driven default values for performance metrics...")

    BEHAVIOR_ADAPTERS = ["ACTION", "LOOK", "CROSS", "OCCLUSION"]
    SCENE_ADAPTERS = ["WEATHER", "TIME_OF_DAY", "PED_DENSITY", "ROAD_PRESENCE"]

    all_gflops_series = []
    if behavior_df is not None:
        for adapter in BEHAVIOR_ADAPTERS:
            gflops_col = f"gflops_{adapter.lower()}"
            if gflops_col in behavior_df.columns:
                all_gflops_series.append(behavior_df[gflops_col].dropna())

    for adapter in SCENE_ADAPTERS:
        gflops_col = f"gflops_{adapter.lower()}"
        if gflops_col in scene_df.columns:
            all_gflops_series.append(scene_df[gflops_col].dropna())

    mean_gflops = pd.concat(all_gflops_series).mean() if all_gflops_series else 0.8
    
    all_times_series = []
    time_adapters_available = ["PED_DENSITY", "ROAD_PRESENCE"]
    for adapter in time_adapters_available:
        time_col = f"pred_{adapter.lower()}_inference_time_ms"
        if time_col in scene_df.columns:
            all_times_series.append(scene_df[time_col].dropna())

    mean_time = pd.concat(all_times_series).mean() if all_times_series else 10.0
    
    defaults = {'time': mean_time, 'gflops': mean_gflops}

    print(f"   - Default GFLOPs set to: {defaults['gflops']:.2f} (average of {len(all_gflops_series)} adapter columns)")
    print(f"   - Default inference time set to: {defaults['time']:.2f} ms (average of {len(all_times_series)} adapter columns)")
    return defaults

# =============================================================================
# B. PERFORMANCE SIMULATION
# =============================================================================

def simulate_approach_performance(scene_df: pd.DataFrame, mode: str, defaults: Dict) -> Dict:
    """
    Simulates the performance of the 'ALL' vs. 'ADAPTIVE' adapter firing strategies.
    
    Args:
        scene_df: DataFrame containing the scene context data.
        mode: The simulation mode ('all' or 'adaptive').
        defaults: A dictionary with fallback values for 'time' and 'gflops'.

    Returns:
        A dictionary of aggregated performance metrics for the specified mode.
    """
    BEHAVIOR_ADAPTERS = ["ACTION", "LOOK", "CROSS", "OCCLUSION"]
    SCENE_ADAPTERS = ["WEATHER", "TIME_OF_DAY", "PED_DENSITY", "ROAD_PRESENCE"]
    ALL_ADAPTERS = BEHAVIOR_ADAPTERS + SCENE_ADAPTERS
    
    adapter_time_cols = {a: f"pred_{a.lower()}_inference_time_ms" for a in ALL_ADAPTERS}
    adapter_gflops_cols = {a: f"gflops_{a.lower()}" for a in ALL_ADAPTERS}

    adapter_usage = {a: 0 for a in ALL_ADAPTERS}
    total_frames = len(scene_df)
    per_frame_times = np.zeros(total_frames)
    per_frame_gflops = np.zeros(total_frames)
    per_frame_adapters = np.zeros(total_frames)

    def get_adapter_time(row, adapter):
        col = adapter_time_cols.get(adapter, "")
        return row.get(col, defaults['time'])

    def get_adapter_gflops(row, adapter):
        col = adapter_gflops_cols.get(adapter, "")
        return row.get(col, defaults['gflops'])

    video_context = {}

    for i, row in scene_df.iterrows():
        video_id = row["video_id"]
        frame_id = row["frame_id"]

        if video_id not in video_context:
            video_context[video_id] = {'last_ped_density': None, 'is_first_frame': True}
        
        is_first_frame = video_context[video_id].get('is_first_frame', True)
        adapters_fired_this_frame = []
        
        if mode == "all":
            adapters_fired_this_frame = BEHAVIOR_ADAPTERS.copy()
            if frame_id % 30 == 0:
                adapters_fired_this_frame.extend(SCENE_ADAPTERS)
        
        else: # ADAPTIVE mode
            if is_first_frame:
                adapters_fired_this_frame.extend(["WEATHER", "TIME_OF_DAY"])
                video_context[video_id]['is_first_frame'] = False
            
            if frame_id % 30 == 0:
                adapters_fired_this_frame.append("PED_DENSITY")
                video_context[video_id]['last_ped_density'] = row.get("pred_ped_density", "low_pedestrian_density")
            
            last_ped_density = video_context[video_id].get('last_ped_density', "low_pedestrian_density")
            weather = row.get("pred_weather", "sunny").lower()
            time_of_day = row.get("pred_time_of_day", "day").lower()
            
            if (time_of_day == "night" or weather in ["rainy", "snowy"] or last_ped_density == "low_pedestrian_density"):
                adapters_fired_this_frame.extend(["ACTION", "LOOK", "CROSS", "OCCLUSION"])
            elif last_ped_density == "medium_pedestrian_density":
                adapters_fired_this_frame.extend(["ACTION", "LOOK", "CROSS", "ROAD_PRESENCE"])
            elif last_ped_density == "high_pedestrian_density" and not (time_of_day == "night" or weather in ["rainy", "snowy"]):
                adapters_fired_this_frame.append("ROAD_PRESENCE")

        adapters_fired_this_frame = list(set(adapters_fired_this_frame))
        per_frame_times[i] = sum(get_adapter_time(row, a) for a in adapters_fired_this_frame)
        per_frame_gflops[i] = sum(get_adapter_gflops(row, a) for a in adapters_fired_this_frame)
        per_frame_adapters[i] = len(adapters_fired_this_frame)
        
        for adapter in adapters_fired_this_frame:
            adapter_usage[adapter] += 1
            
    total_adapters_fired = np.sum(per_frame_adapters)
    
    return {
        "mode": mode.upper(),
        "avg_inference_time_ms": np.mean(per_frame_times),
        "avg_fps": 1000 / np.mean(per_frame_times) if np.mean(per_frame_times) > 0 else 0,
        "avg_gflops": np.mean(per_frame_gflops),
        "avg_adapters_fired_per_frame": np.mean(per_frame_adapters),
        "total_adapters_fired": total_adapters_fired,
        "avg_time_per_active_adapter": np.sum(per_frame_times) / total_adapters_fired if total_adapters_fired > 0 else 0,
        "adapter_utilization": {a: count / total_frames for a, count in adapter_usage.items()}
    }

# =============================================================================
# C. VISUALIZATION & REPORTING
# =============================================================================

def plot_ablation_results(all_metrics: Dict, adaptive_metrics: Dict):
    """Creates and saves a grouped bar plot comparing key performance metrics."""
    import matplotlib.colors as mcolors

    metrics = [
        ("Avg Inference Time (ms)", "avg_inference_time_ms", "lower"),
        ("Avg FPS", "avg_fps", "higher"),
        ("Avg GFLOPs", "avg_gflops", "lower"),
        ("Avg Adapters Fired / Frame", "avg_adapters_fired_per_frame", "lower"),
    ]
    all_vals = [all_metrics[k] for _, k, _ in metrics]
    adaptive_vals = [adaptive_metrics[k] for _, k, _ in metrics]
    
    fig, ax = plt.subplots(figsize=(12, 7))
    x = np.arange(len(metrics))
    width = 0.35

    bars1 = ax.bar(x - width/2, all_vals, width, label='ALL (Baseline)', color=COLORS[0])
    bars2 = ax.bar(x + width/2, adaptive_vals, width, label='ADAPTIVE', color=COLORS[1])

    for i, (name, key, pref) in enumerate(metrics):
        all_val = all_metrics[key]
        adaptive_val = adaptive_metrics[key]
        
        change = ((adaptive_val - all_val) / all_val) * 100 if all_val != 0 else float('inf')
        is_good = (change < 0 and pref == 'lower') or (change > 0 and pref == 'higher')
        color = 'green' if is_good else 'red'
        
        ax.text(bars2[i].get_x() + bars2[i].get_width() / 2, bars2[i].get_height() * 1.01,
                f'{change:+.1f}%', ha='center', va='bottom', fontsize=10, color=color, fontweight='bold')

        ax.bar_label(bars1, fmt='%.2f', padding=3, fontsize=10, fontweight='bold')
        ax.bar_label(bars2, fmt='%.2f', padding=3, fontsize=10, fontweight='bold')
        
    ax.set_ylabel('Value', fontsize=13)
    ax.set_xticks(x)
    ax.set_xticklabels([m[0] for m in metrics], fontsize=12)
    ax.set_title('Ablation Study: ALL (Baseline) vs. ADAPTIVE Approach Performance', fontsize=16, fontweight='bold')
    ax.legend(fontsize=12)
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    fig.tight_layout()
    
    plt.savefig(ABLATION_DIR / "adaptive_vs_all_ablation.png", dpi=300)
    plt.close()
    print(f"\nVisualization saved to '{ABLATION_DIR / 'adaptive_vs_all_ablation.png'}'")

def save_ablation_report(all_metrics: Dict, adaptive_metrics: Dict):
    """Saves a detailed markdown report comparing the two operational modes."""
    with open(ABLATION_DIR / "ablation_report.md", "w") as f:
        f.write("# Ablation Study: ALL (Baseline) vs. ADAPTIVE Approach Performance\n\n")
        f.write("This report compares the performance of the analysis approach when firing all adapters periodically versus using an adaptive, rule-based strategy.\n\n")
        
        f.write("## Performance Summary\n\n")
        f.write("| Metric | ALL (Baseline) | ADAPTIVE | Change |\n")
        f.write("|---|---|---|---|\n")

        def format_row(metric, key, higher_is_better, unit=""):
            all_val = all_metrics[key]
            adaptive_val = adaptive_metrics[key]
            change = ((adaptive_val - all_val) / all_val) * 100 if all_val != 0 else float('inf')
            is_good = (change > 0 and higher_is_better) or (change < 0 and not higher_is_better)
            emoji = "✅" if is_good else "❌"
            return f"| **{metric}** | `{all_val:.2f}{unit}` | `{adaptive_val:.2f}{unit}` | `{change:+.1f}%` {emoji} |\n"
        
        f.write(format_row("Avg Inference Time", "avg_inference_time_ms", False, " ms"))
        f.write(format_row("Avg Processing FPS", "avg_fps", True))
        f.write(format_row("Avg GFLOPs", "avg_gflops", False))
        f.write(format_row("Avg Adapters Fired", "avg_adapters_fired_per_frame", False))
        
        f.write("\n### Adapter Utilization (% of total frames each adapter was fired)\n\n")
        f.write("| Adapter | ALL (Baseline) | ADAPTIVE |\n")
        f.write("|---|---|---|\n")
        for adapter in sorted(all_metrics["adapter_utilization"].keys()):
            all_util = all_metrics["adapter_utilization"][adapter] * 100
            adaptive_util = adaptive_metrics["adapter_utilization"][adapter] * 100
            f.write(f"| {adapter} | `{all_util:.1f}%` | `{adaptive_util:.1f}%` |\n")
            
    print(f"Markdown report saved to '{ABLATION_DIR / 'ablation_report.md'}'")

# =============================================================================
# D. MAIN EXECUTION FLOW
# =============================================================================
def main(scene_csv: str, behavior_csv: Optional[str] = None) -> None:
    """Main execution function to run the complete ablation study."""
    print("=" * 60)
    print(" Starting Ablation Study: ALL (Baseline) vs. ADAPTIVE")
    print("=" * 60)

    ABLATION_DIR.mkdir(parents=True, exist_ok=True)
    
    scene_df, behavior_df = load_ablation_data(scene_csv, behavior_csv)
    default_metrics = calculate_default_metrics(scene_df, behavior_df)

    print("\n[1/2] Simulating 'ALL' mode (baseline)...")
    all_metrics = simulate_approach_performance(scene_df, mode="all", defaults=default_metrics)
    print("   ... 'ALL' mode simulation complete.")

    print("\n[2/2] Simulating 'ADAPTIVE' mode...")
    adaptive_metrics = simulate_approach_performance(scene_df, mode="adaptive", defaults=default_metrics)
    print("   ... 'ADAPTIVE' mode simulation complete.")

    print("\nGenerating report and visualizations...")
    plot_ablation_results(all_metrics, adaptive_metrics)
    save_ablation_report(all_metrics, adaptive_metrics)

    print("\n" + "=" * 60)
    print(" Ablation Study Successfully Completed!")
    print("=" * 60)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run an ablation study comparing a baseline 'ALL' adapter strategy with an 'ADAPTIVE' strategy.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--scene_csv",
        type=str,
        default=os.path.join("Generated_Data", "raw_data_scene_contextual_analysis_step2.csv"),
        help="Path to the scene contextual analysis CSV file from Step 2."
    )
    parser.add_argument(
        "--behavior_csv",
        type=str,
        default=os.path.join("Generated_Data", "raw_data_pedestrian_behavior_step2.csv"),
        help="Path to the pedestrian behavior analysis CSV file from Step 2 (optional)."
    )
    args = parser.parse_args()
    main(args.scene_csv, args.behavior_csv)
