"""
YOLOv8 Fine-Tuning for JAAD Pedestrian Detection

Description:
    This script provides a complete, two-mode pipeline for preparing the JAAD
    dataset and fine-tuning a YOLOv8 model for pedestrian detection. It is
    designed to be run sequentially: first in 'data' mode to create the
    dataset, and then in 'train' mode to perform the actual training.

Operational Modes:
    -   `data` mode:
        1.  Reads the processed annotations CSV from Step 1.
        2.  Extracts individual frames from video clips that contain annotated
            pedestrians.
        3.  Converts the bounding box coordinates into the normalized YOLO format
            (class_id, x_center, y_center, width, height).
        4.  Writes the corresponding .txt label files for each extracted image.
        5.  Splits the dataset into training, validation, and testing sets.
        6.  Generates the `data.yaml` file required by Ultralytics to define
            the dataset structure, classes, and paths.

    -   `train` mode:
        1.  Loads a pre-trained YOLOv8 model (`yolov8l.pt`).
        2.  Initiates the fine-tuning process using the dataset generated by the
            `data` mode.
        3.  Saves training artifacts, including model weights and metrics, to a
            `yolo_jaad_runs/` directory.

Inputs:
    -   Video Clips: Path specified by `--video_folder`.
    -   Processed Annotations CSV (from Step 1): Path specified by `--csv_path`.
    -   Pre-trained YOLOv8 weights (downloaded automatically by Ultralytics).

Outputs:
    -   YOLO Dataset: A structured directory (specified by `--output_root`)
        containing `images/`, `labels/`, and `data.yaml`.
    -   Fine-Tuned Model Weights: Saved in a `yolo_jaad_runs/` directory, with
        the best performing model saved as `best.pt`.
    -   Final Best Model: `best.pt` is copied to the path specified by
        `--final_model_path` for easy access by other scripts.

Command-Line Arguments:
    -   `--mode` (str, required):
        Specifies the operational mode. Must be either 'data' or 'train'.

    -   `--output_root` (str, optional):
        The absolute path to the directory where the generated YOLO dataset
        (images, labels, data.yaml) will be saved.
        Default: "/JAAD_Yolo_Training_Dataset/"

    -   `--csv_path` (str, optional):
        Path to the processed annotations CSV file generated by Step 1.
        Default: "jaad_processed_data_step1.csv"

    -   `--video_folder` (str, optional):
        Path to the folder containing the JAAD video clips.
        Default: "JAAD/JAAD_clips"

    -   `--epochs` (int, optional):
        The number of epochs to run the training for.
        Default: 10

    -   `--final_model_path` (str, optional):
        Full path (including filename) to save the final best model.
        Default: "Best_Model_Configs/yolo_best_model.pt"
"""
import os
import cv2
import yaml
import pandas as pd
from tqdm import tqdm
from ultralytics import YOLO
import shutil
import random
import argparse

# =============================================================================
# A. CONFIGURATION
# =============================================================================
VIDEO_FOLDER   = "JAAD/JAAD_clips"
CSV_PATH       = "jaad_processed_data_step1.csv"
OUTPUT_ROOT    = "/JAAD_Yolo_Training_Dataset/"
EPOCHS         = 10
FINAL_MODEL_PATH = "Best_Model_Configs/yolo_best_model.pt"

# =============================================================================
# B. DATASET CREATION (`data` mode)
# =============================================================================
def create_data(video_folder: str, csv_path: str, output_root: str, class_names: list):
    """
    Extracts frames and creates YOLO formatted labels from the JAAD dataset.
    """
    IMG_DIR   = os.path.join(output_root, "images", "train")
    LBL_DIR   = os.path.join(output_root, "labels", "train")
    os.makedirs(IMG_DIR, exist_ok=True)
    os.makedirs(LBL_DIR, exist_ok=True)

    CLASS_MAP = {name: idx for idx, name in enumerate(class_names)}

    df = pd.read_csv(csv_path)
    df = df[df["label"].isin(CLASS_MAP.keys())]
    grouped = df.groupby(["video_id", "frame_id"])

    print("Extracting frames and writing YOLO-formatted label files...")
    for (vid, fid), rows in tqdm(grouped, total=len(grouped)):
        video_file = os.path.join(video_folder, f"video_{int(vid):04d}.mp4")
        if not os.path.exists(video_file):
            print(f"Warning: Missing video file {video_file}, skipping.")
            continue

        cap = cv2.VideoCapture(video_file)
        cap.set(cv2.CAP_PROP_POS_FRAMES, int(fid))
        ok, frame = cap.read()
        cap.release()

        if not ok:
            continue

        h, w = frame.shape[:2]
        img_name = f"{vid}_{fid}.jpg"
        img_path = os.path.join(IMG_DIR, img_name)
        cv2.imwrite(img_path, frame)

        lbl_lines = []
        for _, r in rows.iterrows():
            xc = (r.bbox_xtl + r.bbox_xbr) / 2 / w
            yc = (r.bbox_ytl + r.bbox_ybr) / 2 / h
            bw = (r.bbox_xbr - r.bbox_xtl) / w
            bh = (r.bbox_ybr - r.bbox_ytl) / h
            cls = CLASS_MAP[r.label]
            lbl_lines.append(f"{cls} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}")

        with open(os.path.join(LBL_DIR, img_name.replace(".jpg", ".txt")), "w") as f:
            f.write("\n".join(lbl_lines))

    print("\nSplitting dataset into train, validation, and test sets...")
    random.seed(42)
    all_images = [f for f in os.listdir(IMG_DIR) if f.endswith('.jpg')]
    random.shuffle(all_images)

    train_ratio = 0.7
    val_ratio = 0.2
    n_total = len(all_images)
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)

    train_images = all_images[:n_train]
    val_images = all_images[n_train:n_train+n_val]
    test_images = all_images[n_train+n_val:]

    def move_files(image_list, split):
        img_dst = os.path.join(output_root, "images", split)
        lbl_dst = os.path.join(output_root, "labels", split)
        os.makedirs(img_dst, exist_ok=True)
        os.makedirs(lbl_dst, exist_ok=True)
        for img in image_list:
            lbl = img.replace('.jpg', '.txt')
            shutil.move(os.path.join(IMG_DIR, img), os.path.join(img_dst, img))
            shutil.move(os.path.join(LBL_DIR, lbl), os.path.join(lbl_dst, lbl))

    move_files(train_images, "train")
    move_files(val_images, "val")
    move_files(test_images, "test")

    print("Creating data.yaml configuration file...")
    data_yaml = {
        "path": os.path.abspath(output_root),
        "train": "images/train",
        "val":   "images/val",
        "test":   "images/test",
        "nc": len(class_names),
        "names": class_names
    }
    with open(os.path.join(output_root, "data.yaml"), "w") as f:
        yaml.safe_dump(data_yaml, f)

    print("\nData creation complete.")

# =============================================================================
# C. MODEL TRAINING (`train` mode)
# =============================================================================
def train_yolo(output_root: str, epochs: int, final_model_path: str):
    """
    Loads a pre-trained YOLOv8 model, starts the fine-tuning process, and
    copies the best performing weights to the final destination.
    """
    print("\nLaunching YOLOv8 training...")
    model = YOLO("yolov8l.pt")
    results = model.train(
        data=os.path.join(output_root, "data.yaml"),
        epochs=epochs,
        imgsz=640,
        batch=16,
        workers=8,
        project="yolo_jaad_runs",
        name=f"yolov8l_{epochs}e",
    )
    print("\nTraining complete.")

    source_model_path = os.path.join(results.save_dir, 'weights', 'best.pt')
    destination_folder = os.path.dirname(final_model_path)

    if not os.path.exists(source_model_path):
        print(f"Error: Trained model 'best.pt' not found at '{source_model_path}'.")
        return

    print(f"\nCopying best model to: {os.path.abspath(final_model_path)}")
    os.makedirs(destination_folder, exist_ok=True)
    shutil.copy(source_model_path, final_model_path)
    print("Model copy successful.")

# =============================================================================
# D. MAIN EXECUTION FLOW
# =============================================================================
def main():
    """
    Parses command-line arguments and runs the selected mode.
    """
    parser = argparse.ArgumentParser(description='YOLOv8 Training Pipeline for JAAD')
    parser.add_argument('--mode', type=str, choices=['data', 'train'], required=True, help='Mode: data (create dataset) or train (train model)')
    parser.add_argument('--output_root', type=str, default=OUTPUT_ROOT, help='Absolute path to the output directory for images, labels, and data.yaml')
    parser.add_argument('--csv_path', type=str, default=CSV_PATH, help='Path to the processed CSV file with bounding boxes and labels')
    parser.add_argument('--video_folder', type=str, default=VIDEO_FOLDER, help='Path to the folder containing JAAD video clips')
    parser.add_argument('--epochs', type=int, default=EPOCHS, help='Number of training epochs')
    parser.add_argument('--final_model_path', type=str, default=FINAL_MODEL_PATH, help='Path to save the final best model.')
    args = parser.parse_args()

    CLASS_NAMES = ["pedestrian", "ped", "people"]

    if args.mode == 'data':
        create_data(args.video_folder, args.csv_path, args.output_root, CLASS_NAMES)
    elif args.mode == 'train':
        train_yolo(args.output_root, args.epochs, args.final_model_path)
    else:
        print(f"Error: Unknown mode '{args.mode}'. Please use 'data' or 'train'.")

if __name__ == "__main__":
    main()

